{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `a.` classification model to predict product category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkContext, SparkConf\n",
    "conf = SparkConf()\n",
    "conf.set('spark.executor.memory', '30g')\n",
    "conf.set('spark.driver.memory', '30g')\n",
    "conf.set(\"spark.executor.instances\", 6)\n",
    "sc = SparkContext(conf=conf)\n",
    "spark = SparkSession.builder.master(\"local\").appName('Classification').config(conf=conf).getOrCreate()\n",
    "spark\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_location = './data/train_test/dataset_en_train.json'\n",
    "df = spark.read.json(file_location)\n",
    "df.show()\n",
    "df.printSchema()\n",
    "df.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess data.\n",
    "df = df.select(\"product_category\", \"review_body\")\n",
    "df = df.na.drop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pyspark.sql.functions import concat_ws\n",
    "# df = df.withColumn(\"text\", concat_ws(\" \", \"review_body\", \"review_title\", \"product_id\"))\n",
    "train_data, test_data = df.randomSplit([0.7, 0.3], seed = 42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "played around with few iterations. considered logistic regression model where i combine product id, review title, and review body in singular column called 'words'. considered an idf with stop words. decided against that as perhaps some of the stop words would be useful. \n",
    "\n",
    "the highest accuracy i got was combining review body, review title, product id into a words column, used stopwords remover and then attempted to get product_category. only got 40% accuracy however....y\n",
    "\n",
    "with current model, only got 30% accuracy but the model is signficantly leaner. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build logistic regression model\n",
    "from pyspark.ml.feature import Tokenizer, StopWordsRemover, CountVectorizer, StringIndexer, HashingTF, IDF, VectorAssembler\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml import Pipeline\n",
    "indexer = StringIndexer(inputCol=\"product_category\", outputCol=\"label\")\n",
    "tokenizer = Tokenizer(inputCol=\"review_body\", outputCol=\"words\")\n",
    "hashing_tf = HashingTF(numFeatures=1000, inputCol=\"words\", outputCol=\"rawFeatures\")\n",
    "idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\")\n",
    "assembler = VectorAssembler(inputCols=[\"features\"], outputCol=\"assembled_features\")\n",
    "\n",
    "lr = LogisticRegression(featuresCol=\"assembled_features\", labelCol=\"label\", maxIter=100, regParam=0.01, elasticNetParam=0.01)\n",
    "pipeline = Pipeline(stages=[indexer, tokenizer, hashing_tf, idf, assembler, lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pipeline.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.transform(test_data)\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol='label', predictionCol='prediction', metricName='accuracy')\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(\"Accuracy: \", accuracy)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `b.` predict customer ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "data = spark.read.json(file_location)\n",
    "data = data.select(col(\"review_id\"), col(\"product_id\"), col(\"reviewer_id\"), col(\"stars\").cast(\"double\"), col(\"review_body\"))\n",
    "(training_data, test_data) = data.randomSplit([0.8, 0.2], seed=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Tokenizer, StopWordsRemover, HashingTF, IDF\n",
    "\n",
    "# Define the stages for the pipeline\n",
    "tokenizer = Tokenizer(inputCol=\"review_body\", outputCol=\"words\")\n",
    "stop_words_remover = StopWordsRemover(inputCol=tokenizer.getOutputCol(), outputCol=\"filtered_words\")\n",
    "hashing_tf = HashingTF(numFeatures=2**16, inputCol=stop_words_remover.getOutputCol(), outputCol=\"tf_features\")\n",
    "idf = IDF(inputCol=hashing_tf.getOutputCol(), outputCol=\"features\")\n",
    "\n",
    "# Create the pipeline\n",
    "from pyspark.ml import Pipeline\n",
    "pipeline = Pipeline(stages=[tokenizer, stop_words_remover, hashing_tf, idf])\n",
    "\n",
    "# Fit the pipeline on the training data\n",
    "pipeline_model = pipeline.fit(training_data)\n",
    "\n",
    "# Transform the training and test data\n",
    "training_data = pipeline_model.transform(training_data)\n",
    "test_data = pipeline_model.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import LinearRegression\n",
    "\n",
    "# Define the linear regression model\n",
    "lr = LinearRegression(featuresCol=\"features\", labelCol=\"stars\", maxIter=10, regParam=0.3, elasticNetParam=0.8)\n",
    "\n",
    "# Train the model on the training data\n",
    "lr_model = lr.fit(training_data)\n",
    "\n",
    "# Make predictions on the test data\n",
    "predictions = lr_model.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-Squared (R2): 0.016053469001464205\n",
      "Root Mean Squared Error (RMSE) = 1.39857\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "# Evaluate the model using RMSE\n",
    "evaluator = RegressionEvaluator(labelCol=\"stars\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "\n",
    "evaluator_r2 = RegressionEvaluator(predictionCol='prediction', labelCol='stars', metricName='r2')\n",
    "r2 = evaluator_r2.evaluate(predictions)\n",
    "\n",
    "print('R-Squared (R2):', r2)\n",
    "print(\"Root Mean Squared Error (RMSE) = %g\" % rmse)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ALA model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error = 3.65522486051963\n",
      "+-----------------+--------------------+\n",
      "|reviewer_id_index|     recommendations|\n",
      "+-----------------+--------------------+\n",
      "|               28|[{9111, 6.524316}...|\n",
      "|               31|[{11573, 7.129544...|\n",
      "|               34|[{2155, 7.886073}...|\n",
      "|               53|[{1557, 7.18665},...|\n",
      "|               65|[{11140, 7.310829...|\n",
      "|               78|[{12164, 7.566792...|\n",
      "|               81|[{10760, 6.494387...|\n",
      "|               85|[{820, 8.648042},...|\n",
      "|              101|[{741, 7.243065},...|\n",
      "|              108|[{12350, 6.405946...|\n",
      "|              115|[{11140, 6.918545...|\n",
      "|              126|[{7546, 7.0045276...|\n",
      "|              133|[{1242, 6.8541527...|\n",
      "|              137|[{948, 7.6337466}...|\n",
      "|              148|[{12148, 6.402157...|\n",
      "|              155|[{1360, 6.8862157...|\n",
      "|              183|[{507, 6.322838},...|\n",
      "|              193|[{3315, 6.109494}...|\n",
      "|              210|[{76, 7.9763365},...|\n",
      "|              211|[{12788, 7.136730...|\n",
      "+-----------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "\n",
    "\n",
    "# Load the data into a Spark DataFrame\n",
    "training_reviews = spark.read.json(file_location)\n",
    "test_reviews = spark.read.json('./data/train_test/dataset_en_test.json')\n",
    "\n",
    "training_reviews = training_reviews.withColumn('stars', training_reviews['stars'].cast('float'))\n",
    "test_reviews = test_reviews.withColumn('stars', test_reviews['stars'].cast('float'))\n",
    "\n",
    "indexer = StringIndexer(inputCol='reviewer_id', outputCol='reviewer_id_index')\n",
    "training_reviews = indexer.fit(training_reviews).transform(training_reviews)\n",
    "test_reviews = indexer.fit(test_reviews).transform(test_reviews)\n",
    "\n",
    "indexer_2 = StringIndexer(inputCol='product_id', outputCol='product_id_index')\n",
    "training_reviews = indexer_2.fit(training_reviews).transform(training_reviews)\n",
    "test_reviews = indexer_2.fit(test_reviews).transform(test_reviews)\n",
    "\n",
    "\n",
    "# Train a collaborative filtering model using ALS algorithm\n",
    "als = ALS(rank=10, maxIter=5, regParam=0.01, userCol=\"reviewer_id_index\", itemCol=\"product_id_index\", ratingCol=\"stars\")\n",
    "model = als.fit(training_reviews)\n",
    "\n",
    "# Evaluate the model on the test data\n",
    "predictions = model.transform(test_reviews)\n",
    "\n",
    "evaluator = RegressionEvaluator(metricName='rmse', labelCol='stars', predictionCol='prediction')\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print('Root Mean Squared Error =', rmse)\n",
    "\n",
    "# Generate top 5 product recommendations for each customer\n",
    "userRecs = model.recommendForAllUsers(5)\n",
    "\n",
    "userRecs.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+--------------------+-----------+----------+\n",
      "|        product_id|    product_category|num_reviews|avg_rating|\n",
      "+------------------+--------------------+-----------+----------+\n",
      "|product_en_0710283|            wireless|          2|       3.0|\n",
      "|product_en_0546607|     lawn_and_garden|          2|       4.0|\n",
      "|product_en_0926827|                 toy|          2|       3.5|\n",
      "|product_en_0828472|           drugstore|          2|       1.5|\n",
      "|product_en_0948054|              beauty|          2|       5.0|\n",
      "|product_en_0448239|               other|          2|       3.0|\n",
      "|product_en_0296897|                 toy|          2|       1.0|\n",
      "|product_en_0496200|             luggage|          2|       3.0|\n",
      "|product_en_0257027|        pet_products|          2|       3.0|\n",
      "|product_en_0719005|    home_improvement|          1|       1.0|\n",
      "|product_en_0575047|    home_improvement|          1|       1.0|\n",
      "|product_en_0478313|digital_ebook_pur...|          1|       2.0|\n",
      "|product_en_0878772|           drugstore|          1|       2.0|\n",
      "|product_en_0022990|            wireless|          1|       3.0|\n",
      "|product_en_0131875|                  pc|          1|       2.0|\n",
      "|product_en_0660162|             apparel|          1|       2.0|\n",
      "|product_en_0742011|        pet_products|          1|       2.0|\n",
      "|product_en_0279685|             kitchen|          1|       2.0|\n",
      "|product_en_0025805|             kitchen|          1|       3.0|\n",
      "|product_en_0427083|            wireless|          1|       3.0|\n",
      "|product_en_0481916|    home_improvement|          1|       3.0|\n",
      "|product_en_0985357|             kitchen|          1|       4.0|\n",
      "|product_en_0440248|           drugstore|          1|       2.0|\n",
      "|product_en_0031692|                 toy|          1|       2.0|\n",
      "|product_en_0287573|                home|          1|       3.0|\n",
      "+------------------+--------------------+-----------+----------+\n",
      "only showing top 25 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1. Identify the most popular products based on the number of reviews and ratings\n",
    "most_popular_products = test_reviews.groupBy([\"product_id\", 'product_category']).agg({\"stars\": \"mean\", \"review_id\": \"count\"}).withColumnRenamed(\"avg(stars)\", \"avg_rating\").withColumnRenamed(\"count(review_id)\", \"num_reviews\").orderBy(col(\"num_reviews\").desc()).show(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------+--------------------+-----------------+\n",
      "|language|num_reviews|avg_predicted_rating|avg_actual_rating|\n",
      "+--------+-----------+--------------------+-----------------+\n",
      "|      en|       5000|-0.01669013895327...|              3.0|\n",
      "+--------+-----------+--------------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 2. Explore the performance of the model on different subsets of the data\n",
    "perf_by_language = predictions.groupBy(\"language\").agg({\"stars\": \"mean\", \"prediction\": \"mean\", \"review_id\": \"count\"}).withColumnRenamed(\"avg(stars)\", \"avg_actual_rating\").withColumnRenamed(\"avg(prediction)\", \"avg_predicted_rating\").withColumnRenamed(\"count(review_id)\", \"num_reviews\").orderBy(col(\"num_reviews\").desc())\n",
    "perf_by_language.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
